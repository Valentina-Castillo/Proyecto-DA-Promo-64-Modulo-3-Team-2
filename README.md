# Vertex Digital Solutions â€” HR Attrition Analytics

## End-to-End Data Pipeline, Relational Modelling & Predictive Analytics

Proyecto acadÃ©mico desarrollado por **Next Level People** como caso prÃ¡ctico de consultorÃ­a para Vertex Digital Solutions, en el marco de un programa formativo en Data Analytics.

ğŸ“Š **PresentaciÃ³n Ejecutiva del Proyecto**

La presentaciÃ³n final del proyecto, incluyendo diagnÃ³stico, modelizaciÃ³n y plan estratÃ©gico, estÃ¡ disponible en el siguiente enlace:  
[Ver presentaciÃ³n en PDF](reports/slides/vertex_HR_Attrition_Presentation.pdf)

---

### 1. Contexto de Negocio

Vertex Digital Solutions detecta un aumento en la rotaciÃ³n de empleados (attrition) y necesita entender los factores que estÃ¡n impulsando la salida del talento. El objetivo no es Ãºnicamente analizar los datos existentes, sino construir una soluciÃ³n estructurada, reproducible y escalable que permita transformar informaciÃ³n dispersa en conocimiento accionable.

La compaÃ±Ã­a solicita:

- DiagnÃ³stico de los drivers de rotaciÃ³n.
- EstandarizaciÃ³n y limpieza del dataset.
- DiseÃ±o de una base de datos relacional normalizada.
- PreparaciÃ³n para modelado predictivo.
- Recomendaciones estratÃ©gicas basadas en evidencia.

---

### 2. Objetivos del Proyecto

- Garantizar calidad y consistencia de datos.
- DiseÃ±ar un modelo relacional en Tercera Forma Normal (3FN).
- Construir un pipeline ETL reproducible en Python.
- Generar un dataset analÃ­ticamente robusto.
- Desarrollar un modelo predictivo de riesgo de attrition (en progreso).

---

### 3. DescripciÃ³n del Dataset

Archivo original: data/raw/hr.csv  
Filas originales: 1474  
Columnas originales: 35  

Tras el proceso de limpieza:

Archivo procesado: data/processed/hr_processed.csv  
Filas finales: 1470  
Columnas finales: 31  
Variable objetivo: attrition (clasificaciÃ³n binaria: Yes/No)

El identificador original (employee_number) se conserva como source_employee_id en la base de datos para mantener trazabilidad.

---

### 4. Arquitectura de la SoluciÃ³n

Flujo completo del proyecto:

RAW CSV  
â†’ Data Cleaning & Feature Engineering (Python)  
â†’ Processed CSV  
â†’ MySQL Database (3FN)  
â†’ Exploratory Analysis  
â†’ Predictive Modelling  

La arquitectura separa claramente las fases de ingesta, transformaciÃ³n, almacenamiento y anÃ¡lisis.

#### Arquitectura del Pipeline de Datos

![Data Pipeline Architecture](docs/data_pipeline_architecture.png)

Este diagrama representa la separaciÃ³n entre las capas de ingesta, transformaciÃ³n, almacenamiento relacional y consumo analÃ­tico.

---

### 5. Estructura del Repositorio

```text
PROYECTO-DA-PROMO-64-MODULO-3-TEAM-2/
â”‚
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ fonts/ # TipografÃ­as utilizadas en visualizaciones y presentaciÃ³n
â”‚ â””â”€â”€ static/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”‚ â””â”€â”€ hr.csv # Dataset original
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ hr_processed.csv # Dataset transformado y preparado para modelado y carga
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ data_pipeline_architecture.png
â”‚ â”œâ”€â”€ data_quality_report.md
â”‚ â””â”€â”€ edr_nextlevel_people.png # Diagrama entidad-relaciÃ³n (BBDD)
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 00_EDA.ipynb
â”‚ â”œâ”€â”€ 01_Limpieza.ipynb
â”‚ â”œâ”€â”€ 02_AnÃ¡lisis_Descriptivo.ipynb
â”‚ â””â”€â”€ 03_AnÃ¡lisis_Inferencial.ipynb
â”‚
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ figures/ # Visualizaciones exportadas
â”‚ â”‚ â”œâ”€â”€ 00_eda/
â”‚ â”‚ â”œâ”€â”€ 01_anÃ¡lisis_estadÃ­stico/
â”‚ â”‚ â””â”€â”€ 02_anÃ¡lisis_inferencial/
â”‚ â””â”€â”€ slides/
â”‚ â””â”€â”€ vertex_HR_Attrition_Presentation.pdf
â”‚
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ 01_create_schema_nextlevel_people.sql
â”‚ â””â”€â”€ 02_eda_load_validation.sql
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ cleaning_core.py # Funciones principales de limpieza
â”‚ â”œâ”€â”€ imputation.py # Tratamiento de valores nulos
â”‚ â”œâ”€â”€ ordinal_mapping.py # Mapeo de variables ordinales
â”‚ â”œâ”€â”€ load_mysql.py # Carga de datos en MySQL
â”‚ â”œâ”€â”€ main.py # OrquestaciÃ³n del proceso
â”‚ â””â”€â”€ pipeline.py # DefiniciÃ³n del flujo ETL
â”‚
â”œâ”€â”€ README.md # DocumentaciÃ³n principal del proyecto
â””â”€â”€ requirements.txt # Dependencias del entorno
```

---

### 6. Limpieza y PreparaciÃ³n de Datos

El pipeline implementa:

- NormalizaciÃ³n de nombres de columnas a snake_case.
- CorrecciÃ³n de inconsistencias en valores categÃ³ricos.
- EstandarizaciÃ³n de escalas ordinales (satisfacciÃ³n, educaciÃ³n, job level, stock options, performance rating).
- Tratamiento de valores nulos segÃºn tipologÃ­a de variable.
- ConversiÃ³n explÃ­cita de tipos para asegurar consistencia en la carga a SQL.
- PreparaciÃ³n del dataset para anÃ¡lisis descriptivo y modelado predictivo.

La lÃ³gica de transformaciÃ³n se encuentra modularizada en src/cleaning_core.py, src/imputation.py y src/ordinal_mapping.py.

---

### 7. DiseÃ±o de Base de Datos (MySQL â€” 3FN)

Base de datos: nextlevel_people

Tablas dimensiÃ³n:

- departments
- job_roles
- education_fields
- business_travel_types
- marital_statuses
- genders

Tabla principal:

employees

Incluye:

- employee_id (Primary Key autoincrement)
- source_employee_id (Ãºnico para trazabilidad)
- Foreign Keys a tablas dimensiÃ³n
- Variables numÃ©ricas y flags
- Restricciones CHECK para garantizar integridad de datos

El diseÃ±o en Tercera Forma Normal elimina redundancia y asegura consistencia relacional.

#### Diagrama Entidad-RelaciÃ³n (ERD)

![ERD NextLevel People](docs/edr_nextlevel_people.png)

Este diagrama refleja la estructura relacional normalizada y las relaciones entre la tabla principal y las tablas dimensiÃ³n.

---

### 8. Pipeline ETL (Python)

El archivo src/main.py orquesta el flujo completo:

1. Lectura del CSV raw.
2. EjecuciÃ³n del pipeline de limpieza.
3. GeneraciÃ³n del CSV procesado.
4. Carga estructurada a MySQL mediante SQLAlchemy.

El sistema permite ejecutar el flujo completo de manera reproducible desde la raÃ­z del proyecto.  
El diseÃ±o modular facilita la mantenibilidad, escalabilidad y reutilizaciÃ³n del pipeline.

---

### 9. AnÃ¡lisis Exploratorio

Notebook: notebooks/02_Analisis_Descriptivo.ipynb

El anÃ¡lisis descriptivo tuvo como objetivo caracterizar el fenÃ³meno de attrition antes de avanzar hacia la modelizaciÃ³n explicativa.

Principales hallazgos:

- El attrition se concentra en etapas tempranas de carrera, especialmente en Entry Level y perfiles con menor seniority.
- Factores operativos como overtime, viajes frecuentes y baja satisfacciÃ³n laboral muestran asociaciÃ³n recurrente con mayores tasas de salida.
- Variables estructurales como departamento, rol y nivel organizativo segmentan claramente el riesgo.
- La compensaciÃ³n econÃ³mica influye principalmente en fases iniciales y contextos especÃ­ficos, aunque no explica por sÃ­ sola el comportamiento global.
- Se observan fricciones potenciales en posicionamiento salarial, con solapamiento entre niveles jerÃ¡rquicos.
- El clima organizacional agregado muestra relaciÃ³n significativa con el attrition.
- El fenÃ³meno presenta naturaleza multifactorial, con combinaciones de variables que generan hotspots concretos.

Este anÃ¡lisis permitiÃ³ establecer una base estructurada para la posterior modelizaciÃ³n explicativa.

---

### 10. Modelado Predictivo

Notebook: notebooks/03_Modelo_Predictivo.ipynb

A partir de los hallazgos descriptivos, se desarrollÃ³ un enfoque explicativo orientado a comprender los drivers estructurales del attrition y estimar el riesgo asociado a cada perfil organizativo.

El proceso incluyÃ³:

- ImplementaciÃ³n de regresiÃ³n logÃ­stica para cuantificar la relaciÃ³n entre variables operativas y estructurales y la probabilidad de attrition.
- Interpretabilidad mediante anÃ¡lisis SHAP para identificar la contribuciÃ³n especÃ­fica de cada variable tanto a nivel global como individual.
- SegmentaciÃ³n mediante clustering basado en patrones explicativos, permitiendo identificar perfiles organizativos con distintos niveles de exposiciÃ³n al riesgo.

Este enfoque permitiÃ³ pasar de la identificaciÃ³n de correlaciones descriptivas a una comprensiÃ³n estructurada de los factores que incrementan la probabilidad de abandono, habilitando perfiles de riesgo interpretables y accionables.

---

### 11. Impacto en el Negocio

El anÃ¡lisis descriptivo y la modelizaciÃ³n explicativa permiten traducir los hallazgos tÃ©cnicos en implicaciones estratÃ©gicas para la organizaciÃ³n.

Principales aportaciones:

- IdentificaciÃ³n de perfiles organizativos con distinto nivel de exposiciÃ³n al riesgo de attrition.
- ConfirmaciÃ³n de que el fenÃ³meno no es homogÃ©neo, sino segmentado por rol, nivel y trayectoria profesional.
- IdentificaciÃ³n de drivers estructurales asociados a mayor probabilidad de abandono (overtime, baja satisfacciÃ³n, progresiÃ³n limitada y condiciones del rol).
- SegmentaciÃ³n en clusters diferenciados que permiten priorizar intervenciones segÃºn perfil organizativo.

Estos resultados permiten pasar de una percepciÃ³n general de â€œalta rotaciÃ³nâ€ a una comprensiÃ³n estructurada y segmentada del fenÃ³meno, habilitando estrategias de retenciÃ³n dirigidas.

Las recomendaciones propuestas se organizan en corto, medio y largo plazo, combinando medidas de contenciÃ³n inmediata, estabilizaciÃ³n organizativa y desarrollo estructural del talento.

---

### 12. TecnologÃ­as Utilizadas

#### Programming & Data Processing

- Python 3.x
- Pandas
- NumPy

#### Data Visualization

- Matplotlib
- Seaborn

#### Machine Learning (in progress)

- Scikit-learn

#### Database & Data Modelling

- MySQL 8.x
- MySQL Workbench
- SQLAlchemy

#### Development & Version Control

- Jupyter Notebook
- Git
- GitHub

---

### 13. Limitaciones y EvoluciÃ³n del Proyecto

El proyecto implementa un pipeline completo end-to-end que integra anÃ¡lisis exploratorio, modelado predictivo, diseÃ±o de base de datos relacional y automatizaciÃ³n mediante ETL.

No obstante, su evoluciÃ³n hacia un entorno productivo podrÃ­a contemplar las siguientes mejoras estratÃ©gicas:

- IntegraciÃ³n automÃ¡tica con fuentes dinÃ¡micas de datos para permitir actualizaciones periÃ³dicas sin intervenciÃ³n manual.
- Enriquecimiento del modelo predictivo mediante la incorporaciÃ³n de nuevas variables estratÃ©gicas (desempeÃ±o, clima organizativo, indicadores de productividad).
- EvoluciÃ³n hacia un enfoque de Machine Learning con reentrenamiento periÃ³dico y validaciÃ³n continua del rendimiento del modelo.
- Desarrollo de un dashboard interactivo (Power BI o Tableau) para facilitar la toma de decisiones en tiempo real por parte de direcciÃ³n y RRHH.
- ImplementaciÃ³n de validaciones automÃ¡ticas de calidad de datos previas a la carga.
- IncorporaciÃ³n de logging estructurado y gestiÃ³n segura de credenciales mediante variables de entorno.
- InclusiÃ³n de tests unitarios para reforzar la robustez y mantenibilidad del pipeline.

Estas lÃ­neas de evoluciÃ³n permitirÃ­an consolidar el proyecto como un sistema escalable, automatizado y plenamente integrado en la estrategia de gestiÃ³n del talento.

---

### 14. CÃ³mo Reproducir el Proyecto

1. Crear entorno virtual:

    python -m venv .venv

    ActivaciÃ³n:

    Windows:
    .venv\Scripts\Activate.ps1

    Mac/Linux:
    source .venv/bin/activate

2. Instalar dependencias:

    pip install -r requirements.txt

3. Crear esquema MySQL ejecutando:

    sql/01_create_schema_nextlevel_people.sql

4. Ejecutar pipeline completo desde la raÃ­z del proyecto:

    python src/main.py

Esto generarÃ¡ data/processed/hr_processed.csv y cargarÃ¡ las dimensiones y la tabla employees en la base de datos nextlevel_people.

ValidaciÃ³n opcional:

sql/02_eda_load_validation.sql

---

### 15. Equipo â€” Next Level People

Scrum Master  
Valentina Castillo  
CoordinaciÃ³n & MetodologÃ­a Ãgil  
PlanificaciÃ³n de sprints, organizaciÃ³n del equipo y seguimiento estratÃ©gico del proyecto.  
[LinkedIn](https://www.linkedin.com/in/valentina-castillo-escobar-191863202/) | [GitHub](https://github.com/Valentina-Castillo)

Data Team  
Arantxa Barea  
AnÃ¡lisis & Modelado  
ExploraciÃ³n de datos, generaciÃ³n de insights, anÃ¡lisis exploratorio y predictivo.  
[LinkedIn](https://www.linkedin.com/in/arantxa-barea/) | [GitHub](https://github.com/arantxa-90)

Data Team  
Nieves SÃ¡nchez  
Arquitectura & AutomatizaciÃ³n  
DiseÃ±o de base de datos, estructuraciÃ³n del repositorio, desarrollo de la ETL y documentaciÃ³n.  
[LinkedIn](https://www.linkedin.com/in/nieves-sanchez-data) | [GitHub](https://github.com/nieves-sanchez)

---

### 16. Estado del Proyecto

Pipeline de datos: Completado  
Modelado de base de datos: Completado  
AnÃ¡lisis exploratorio: Completado
Modelado predictivo: Completado
PresentaciÃ³n final: Completado

---

### 17. Aviso Legal

Proyecto desarrollado con fines educativos y de portfolio.  
No contiene datos reales de empleados ni informaciÃ³n sensible empresarial.
