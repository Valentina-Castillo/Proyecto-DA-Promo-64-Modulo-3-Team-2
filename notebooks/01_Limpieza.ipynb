{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf1c995",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a1501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "192618a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35c894fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>Over18</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>sALES eXECUTIVE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>5993.0</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>rESEARCH sCIENTIST</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>No</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>lABORATORY tECHNICIAN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0  41.0       Yes      Travel_Rarely       1102                   Sales   \n",
       "1  49.0        No  Travel_Frequently        279  Research & Development   \n",
       "2  37.0       Yes      Travel_Rarely       1373  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "\n",
       "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                        2  Female          94               3         2   \n",
       "1                        3    Male          61               2         2   \n",
       "2                        4    Male          92               2         1   \n",
       "\n",
       "                   JobRole  JobSatisfaction MaritalStatus  MonthlyIncome  \\\n",
       "0         sALES eXECUTIVE               4.0        Single         5993.0   \n",
       "1      rESEARCH sCIENTIST               2.0       Married         5130.0   \n",
       "2   lABORATORY tECHNICIAN               3.0        Single         2090.0   \n",
       "\n",
       "   MonthlyRate  NumCompaniesWorked Over18 OverTime  PercentSalaryHike  \\\n",
       "0        19479                   8      Y      Yes                 11   \n",
       "1        24907                   1      Y       No                 23   \n",
       "2         2396                   6      Y      Yes                 15   \n",
       "\n",
       "   PerformanceRating  RelationshipSatisfaction  StandardHours  \\\n",
       "0                  3                         1           80.0   \n",
       "1                  4                         4            NaN   \n",
       "2                  3                         2            NaN   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                 0                  8                    0.0   \n",
       "1                 1                 10                    3.0   \n",
       "2                 0                  7                    3.0   \n",
       "\n",
       "   WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                1               6                   4   \n",
       "1                3              10                   7   \n",
       "2                3               0                   0   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                        0                   5.0  \n",
       "1                        1                   7.0  \n",
       "2                        0                   0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/hr.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0e0cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_nombres_columnas(lista_columnas, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Normaliza una lista de nombres de columnas de DataFrame.\n",
    "    \n",
    "    Esta normalizaci√≥n incluye:\n",
    "    - Eliminaci√≥n de espacios al inicio y al final\n",
    "    - Eliminaci√≥n de caracteres especiales (excepto guiones bajos)\n",
    "    - Conversi√≥n de CamelCase o PascalCase a snake_case\n",
    "    - Conversi√≥n de todos los caracteres a min√∫sculas\n",
    "    \n",
    "    Par√°metros:\n",
    "    - lista_columnas: lista de strings con nombres de columnas originales\n",
    "    - mostrar_resumen: bool, si True imprime un resumen de los cambios\n",
    "    \n",
    "    Retorna:\n",
    "    - lista de nombres de columnas normalizados en snake_case\n",
    "    \"\"\"\n",
    "    nombres_normalizados = []\n",
    "    \n",
    "    for nombre in lista_columnas:\n",
    "        limpia = nombre.strip()  # quitar espacios al inicio y final\n",
    "        limpia = re.sub(r'[^0-9a-zA-Z_]', '', limpia)  # eliminar caracteres especiales salvo guion bajo\n",
    "        limpia = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', limpia) # insertar guion bajo entre min√∫scula/n√∫mero y may√∫scula\n",
    "        nombres_normalizados.append(limpia.lower())  # convertir a min√∫sculas\n",
    "\n",
    "    # Mostrar resumen opcional\n",
    "    if mostrar_resumen:\n",
    "        print(\"Normalizaci√≥n de nombres de columnas finalizada.\")\n",
    "        print(f\"Total columnas procesadas: {len(nombres_normalizados)}\")\n",
    "        print(\"Resumen de cambios:\")\n",
    "        for orig, nuevo in zip(lista_columnas, nombres_normalizados):\n",
    "            print(f\"'{orig}' -> '{nuevo}'\")\n",
    "    \n",
    "    return nombres_normalizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "897cb4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizaci√≥n de nombres de columnas finalizada.\n",
      "Total columnas procesadas: 35\n",
      "Resumen de cambios:\n",
      "'Age' -> 'age'\n",
      "'Attrition' -> 'attrition'\n",
      "'BusinessTravel' -> 'business_travel'\n",
      "'DailyRate' -> 'daily_rate'\n",
      "'Department' -> 'department'\n",
      "'DistanceFromHome' -> 'distance_from_home'\n",
      "'Education' -> 'education'\n",
      "'EducationField' -> 'education_field'\n",
      "'EmployeeCount' -> 'employee_count'\n",
      "'EmployeeNumber' -> 'employee_number'\n",
      "'EnvironmentSatisfaction' -> 'environment_satisfaction'\n",
      "'Gender' -> 'gender'\n",
      "'HourlyRate' -> 'hourly_rate'\n",
      "'JobInvolvement' -> 'job_involvement'\n",
      "'JobLevel' -> 'job_level'\n",
      "'JobRole' -> 'job_role'\n",
      "'JobSatisfaction' -> 'job_satisfaction'\n",
      "'MaritalStatus' -> 'marital_status'\n",
      "'MonthlyIncome' -> 'monthly_income'\n",
      "'MonthlyRate' -> 'monthly_rate'\n",
      "'NumCompaniesWorked' -> 'num_companies_worked'\n",
      "'Over18' -> 'over18'\n",
      "'OverTime' -> 'over_time'\n",
      "'PercentSalaryHike' -> 'percent_salary_hike'\n",
      "'PerformanceRating' -> 'performance_rating'\n",
      "'RelationshipSatisfaction' -> 'relationship_satisfaction'\n",
      "'StandardHours' -> 'standard_hours'\n",
      "'StockOptionLevel' -> 'stock_option_level'\n",
      "'TotalWorkingYears' -> 'total_working_years'\n",
      "'TrainingTimesLastYear' -> 'training_times_last_year'\n",
      "'WorkLifeBalance' -> 'work_life_balance'\n",
      "'YearsAtCompany' -> 'years_at_company'\n",
      "'YearsInCurrentRole' -> 'years_in_current_role'\n",
      "'YearsSinceLastPromotion' -> 'years_since_last_promotion'\n",
      "'YearsWithCurrManager' -> 'years_with_curr_manager'\n"
     ]
    }
   ],
   "source": [
    "df.columns = normalizar_nombres_columnas(df.columns.tolist(), mostrar_resumen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b27a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usar_columna_como_indice(df, columna_original='employee_number', indice='id'):\n",
    "    \"\"\"\n",
    "    Establece una columna del DataFrame como √≠ndice del mismo\n",
    "    y la renombra como 'id' u otro nombre especificado.\n",
    "    \n",
    "    Par√°metros:\n",
    "    - df: DataFrame a modificar\n",
    "    - columna_original: nombre de la columna a usar como √≠ndice\n",
    "    - nuevo_nombre: nombre corto que se asignar√° al √≠ndice\n",
    "    \n",
    "    Retorna:\n",
    "    - DataFrame con la columna establecida como √≠ndice y renombrada\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Verificar que la columna exista\n",
    "    if columna_original not in df.columns:\n",
    "        raise ValueError(f\"La columna '{columna_original}' no existe en el DataFrame.\")\n",
    "    \n",
    "    # Renombrar columna\n",
    "    df.rename(columns={columna_original: indice}, inplace=True)\n",
    "    \n",
    "    # Establecer como √≠ndice\n",
    "    df.set_index(indice, inplace=True)\n",
    "    \n",
    "    print(f\"Columna '{columna_original}' renombrada a '{indice}' y establecida como √≠ndice correctamente.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b72d0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'employee_number' renombrada a 'id' y establecida como √≠ndice correctamente.\n"
     ]
    }
   ],
   "source": [
    "df = usar_columna_como_indice(df, columna_original='employee_number', indice='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5edba930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_filas_duplicadas(df, keep='first'):\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas del DataFrame.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame a procesar\n",
    "    - keep: define qu√© duplicados conservar\n",
    "        'first'  -> conserva la primera aparici√≥n\n",
    "        'last'   -> conserva la √∫ltima aparici√≥n\n",
    "        False    -> elimina todas las filas duplicadas\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame sin filas duplicadas\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    num_filas_antes_limpieza = df.shape[0]\n",
    "\n",
    "    # Eliminar filas duplicadas seg√∫n el par√°metro 'keep'\n",
    "    df.drop_duplicates(keep=keep, inplace=True)\n",
    "\n",
    "    # Calcular cu√°ntas filas se eliminaron\n",
    "    filas_eliminadas = num_filas_antes_limpieza - df.shape[0]\n",
    "\n",
    "    print(f\"Filas antes de eliminar duplicados: {num_filas_antes_limpieza}\")\n",
    "    print(f\"Filas eliminadas por duplicados: {filas_eliminadas}\")\n",
    "    print(f\"Filas en el DataFrame tras el procesamiento: {df.shape[0]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "568960c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas antes de eliminar duplicados: 1474\n",
      "Filas eliminadas por duplicados: 4\n",
      "Filas en el DataFrame tras el procesamiento: 1470\n"
     ]
    }
   ],
   "source": [
    "df = eliminar_filas_duplicadas(df, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb35f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas_sin_aporte_analitico(df, umbral_cardinalidad=0.95):\n",
    "    \"\"\"\n",
    "    Elimina columnas del DataFrame que no aportan valor anal√≠tico:\n",
    "    - Columnas constantes (todos los valores iguales)\n",
    "    - Columnas con alta cardinalidad (proporci√≥n de valores √∫nicos mayor al umbral). \n",
    "    Se considera alta cardinalidad si es superior a 0.95\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame a limpiar\n",
    "    - umbral_cardinalidad: proporci√≥n m√°xima de valores √∫nicos permitida (float entre 0 y 1)\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con las columnas constantes o de alta cardinalidad eliminadas\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    columnas_a_eliminar = []\n",
    "\n",
    "    \n",
    "    for columna in df.columns:\n",
    "        # Columna constante\n",
    "        if df[columna].nunique() == 1:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "        # Columna con alta cardinalidad\n",
    "        elif df[columna].nunique() / len(df) > umbral_cardinalidad:\n",
    "            columnas_a_eliminar.append(columna)\n",
    "\n",
    "    # Eliminar columnas identificadas\n",
    "    df.drop(columns=columnas_a_eliminar, inplace=True)\n",
    "\n",
    "    print(f\"Columnas eliminadas por no aportar valor anal√≠tico: {columnas_a_eliminar}\")\n",
    "    print(f\"Total columnas eliminadas: {len(columnas_a_eliminar)}\")\n",
    "    print(f\"Columnas restantes en el DataFrame: {df.shape[1]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6936ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas por no aportar valor anal√≠tico: ['employee_count', 'monthly_rate', 'over18', 'standard_hours']\n",
      "Total columnas eliminadas: 4\n",
      "Columnas restantes en el DataFrame: 30\n"
     ]
    }
   ],
   "source": [
    "df = eliminar_columnas_sin_aporte_analitico(df, umbral_cardinalidad=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6468f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_columnas_texto(df, mapeos_reemplazo=None, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Normaliza columnas de texto o categ√≥ricas y aplica mapeos de reemplazo opcionales.\n",
    "\n",
    "    Pasos de normalizaci√≥n:\n",
    "    1. Elimina espacios al inicio y al final de cada valor.\n",
    "    2. Convierte el texto a 'Title Case' (primera letra may√∫scula, resto min√∫scula).\n",
    "    3. Aplica mapeos de reemplazo si se proporciona un diccionario (para casos espec√≠ficos).\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: DataFrame a limpiar (debe ser un pd.DataFrame)\n",
    "    - mapeos_reemplazo: diccionario opcional con claves como nombres de columnas\n",
    "      y valores como diccionarios de reemplazo {'valor_antiguo': 'valor_nuevo'}\n",
    "    - mostrar_resumen: bool, si True imprime resumen de columnas procesadas y categor√≠as\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con columnas de texto normalizadas\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    columnas_texto = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    columnas_con_reemplazo = []\n",
    "\n",
    "    for col in columnas_texto:\n",
    "        # Eliminar espacios y pasar a Title Case\n",
    "        df[col] = df[col].str.strip().str.title()\n",
    "\n",
    "        # Aplicar mapeos de reemplazo si existen\n",
    "        if mapeos_reemplazo and col in mapeos_reemplazo:\n",
    "            df[col] = df[col].replace(mapeos_reemplazo[col])\n",
    "            columnas_con_reemplazo.append(col)\n",
    "\n",
    "    # Mostrar resumen opcional\n",
    "    if mostrar_resumen:\n",
    "        print(\"Normalizaci√≥n de columnas de texto finalizada.\")\n",
    "        print(f\"Columnas procesadas: {columnas_texto}\")\n",
    "\n",
    "        if columnas_con_reemplazo:\n",
    "            print(f\"Se aplicaron mapeos de reemplazo en: {columnas_con_reemplazo}\")\n",
    "            for col in columnas_con_reemplazo:\n",
    "                print(f\"Categor√≠as finales de '{col}': {df[col].unique().tolist()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fccee631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizaci√≥n de columnas de texto finalizada.\n",
      "Columnas procesadas: ['attrition', 'business_travel', 'department', 'education_field', 'gender', 'job_role', 'marital_status', 'over_time']\n",
      "Se aplicaron mapeos de reemplazo en: ['business_travel', 'marital_status']\n",
      "Categor√≠as finales de 'business_travel': ['Rarely', 'Frequently', 'Non', nan]\n",
      "Categor√≠as finales de 'marital_status': ['Single', 'Married', 'Divorced', nan]\n"
     ]
    }
   ],
   "source": [
    "mapeos_reemplazo = {\n",
    "    'marital_status': {'Marreid': 'Married'},  # corregir typo\n",
    "    'business_travel': {\n",
    "        'Travel_Rarely': 'Rarely',\n",
    "        'Travel_Frequently': 'Frequently',\n",
    "        'Non-Travel': 'Non'\n",
    "    }\n",
    "}\n",
    "\n",
    "df = normalizar_columnas_texto(df, mapeos_reemplazo=mapeos_reemplazo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "133e371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_tipos_columnas(df, mapeo_tipos, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Convierte columnas de un DataFrame a tipos de datos espec√≠ficos.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: pd.DataFrame a modificar\n",
    "    - mapeo_tipos: diccionario con claves como nombres de columnas y\n",
    "      valores como tipos de datos deseados (ej. int, float, 'Int64', 'category')\n",
    "    - mostrar_resumen: bool, si True imprime un resumen de columnas convertidas\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con columnas convertidas a los tipos especificados\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    columnas_convertidas = []\n",
    "\n",
    "    for columna, tipo in mapeo_tipos.items():\n",
    "        if columna in df.columns:\n",
    "            try:\n",
    "                df[columna] = df[columna].astype(tipo, errors='ignore')\n",
    "                columnas_convertidas.append(columna)\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo convertir la columna '{columna}' a {tipo}: {e}\")\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"Conversi√≥n de tipos finalizada.\")\n",
    "        if columnas_convertidas:\n",
    "            print(f\"Columnas convertidas: {columnas_convertidas}\")\n",
    "        else:\n",
    "            print(\"No se convirti√≥ ninguna columna.\")\n",
    "\n",
    "        # Mostrar todas las columnas con su tipo de dato final\n",
    "        print(\"\\nTipos de datos finales por columna:\")\n",
    "        tipos_finales = pd.DataFrame({\n",
    "            \"Columna\": df.columns,\n",
    "            \"Tipo de dato\": [df[col].dtype for col in df.columns]\n",
    "        })\n",
    "        display(tipos_finales)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb47520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversi√≥n de tipos finalizada.\n",
      "Columnas convertidas: ['age', 'daily_rate', 'hourly_rate', 'training_times_last_year', 'years_with_curr_manager']\n",
      "\n",
      "Tipos de datos finales por columna:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columna</th>\n",
       "      <th>Tipo de dato</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attrition</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business_travel</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daily_rate</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>distance_from_home</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>education</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>education_field</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>environment_satisfaction</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gender</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hourly_rate</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job_involvement</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>job_level</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>job_role</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>job_satisfaction</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>monthly_income</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_companies_worked</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>over_time</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>percent_salary_hike</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>performance_rating</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>relationship_satisfaction</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stock_option_level</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total_working_years</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>training_times_last_year</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>work_life_balance</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>years_at_company</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>years_in_current_role</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>years_since_last_promotion</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>years_with_curr_manager</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Columna Tipo de dato\n",
       "0                          age        Int64\n",
       "1                    attrition       object\n",
       "2              business_travel       object\n",
       "3                   daily_rate      float64\n",
       "4                   department       object\n",
       "5           distance_from_home        int64\n",
       "6                    education        int64\n",
       "7              education_field       object\n",
       "8     environment_satisfaction        int64\n",
       "9                       gender       object\n",
       "10                 hourly_rate      float64\n",
       "11             job_involvement        int64\n",
       "12                   job_level        int64\n",
       "13                    job_role       object\n",
       "14            job_satisfaction      float64\n",
       "15              marital_status       object\n",
       "16              monthly_income      float64\n",
       "17        num_companies_worked        int64\n",
       "18                   over_time       object\n",
       "19         percent_salary_hike        int64\n",
       "20          performance_rating        int64\n",
       "21   relationship_satisfaction        int64\n",
       "22          stock_option_level        int64\n",
       "23         total_working_years        int64\n",
       "24    training_times_last_year        Int64\n",
       "25           work_life_balance        int64\n",
       "26            years_at_company        int64\n",
       "27       years_in_current_role        int64\n",
       "28  years_since_last_promotion        int64\n",
       "29     years_with_curr_manager        Int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapeo_tipos = {\n",
    "    \"age\": \"Int64\",\n",
    "    \"daily_rate\": float,\n",
    "    \"hourly_rate\": float,\n",
    "    \"monthly_rate\": float,\n",
    "    \"training_times_last_year\": \"Int64\",\n",
    "    \"years_with_curr_manager\": \"Int64\",\n",
    "}\n",
    "\n",
    "df = convertir_tipos_columnas(df, mapeo_tipos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48a799fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_columnas_ordinales(df, mapeo_ordinal, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Aplica un mapeo sem√°ntico a columnas ordinales de un DataFrame.\n",
    "\n",
    "    Pasos:\n",
    "    1. Reemplaza los valores num√©ricos de las columnas ordinales por etiquetas sem√°nticas.\n",
    "    2. Permite mostrar un resumen de las columnas mapeadas.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: pd.DataFrame a modificar\n",
    "    - mapeo_ordinal: diccionario donde las claves son nombres de columnas y los valores\n",
    "      son diccionarios de mapeo {valor_original: valor_nuevo}\n",
    "    - mostrar_resumen: bool, si True imprime qu√© columnas se han mapeado\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con las columnas ordinales mapeadas\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    columnas_mapeadas = []\n",
    "\n",
    "    for columna, mapping in mapeo_ordinal.items():\n",
    "        if columna in df.columns:\n",
    "            df[columna] = df[columna].map(mapping)\n",
    "            columnas_mapeadas.append(columna)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"üîπ Mapeo de columnas ordinales finalizado.\")\n",
    "        if columnas_mapeadas:\n",
    "            print(f\"Columnas mapeadas: {columnas_mapeadas}\")\n",
    "        else:\n",
    "            print(\"No se aplic√≥ mapeo a ninguna columna.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "041fac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_columnas_ordinales(df, mapeos_columnas, mostrar_resumen=True):\n",
    "    \"\"\"\n",
    "    Aplica mapeo sem√°ntico a columnas ordinales del DataFrame seg√∫n un diccionario proporcionado.\n",
    "\n",
    "    Par√°metros:\n",
    "    - df: pd.DataFrame a modificar\n",
    "    - mapeos_columnas: diccionario con claves como nombres de columnas y valores como diccionarios de mapeo.\n",
    "                       Ejemplo:\n",
    "                       {\n",
    "                           \"education\": {1: \"Sin estudios\", 2: \"Educaci√≥n b√°sica\", ...},\n",
    "                           \"job_level\": {1: \"Becario\", 2: \"Junior\", ...}\n",
    "                       }\n",
    "    - mostrar_resumen: bool, si True imprime resumen de columnas mapeadas y sus valores √∫nicos.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con columnas ordinales mapeadas\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    columnas_mapeadas = []\n",
    "\n",
    "    for columna, mapa in mapeos_columnas.items():\n",
    "        if columna in df.columns:\n",
    "            df[columna] = df[columna].map(mapa)\n",
    "            columnas_mapeadas.append(columna)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"üîπ Mapeo de columnas ordinales finalizado.\")\n",
    "        print(f\"Columnas mapeadas: {columnas_mapeadas}\")\n",
    "        for col in columnas_mapeadas:\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4aaa671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Mapeo de columnas ordinales finalizado.\n",
      "Columnas mapeadas: ['job_involvement', 'job_satisfaction', 'work_life_balance', 'education', 'job_level']\n",
      "job_involvement: ['Satisfecho' 'Insatisfecho' 'Muy satisfecho' 'Nada satisfecho']\n",
      "job_satisfaction: ['Muy satisfecho' 'Insatisfecho' 'Satisfecho' 'Nada satisfecho' nan]\n",
      "work_life_balance: ['Nada satisfecho' 'Satisfecho' 'Insatisfecho' 'Muy satisfecho']\n",
      "education: ['Educaci√≥n b√°sica' 'Sin estudios' 'Estudios universitarios'\n",
      " 'FP/Bachiller' 'Postgrado']\n",
      "job_level: ['Junior' 'Becario' 'Senior' 'Manager' 'Director']\n"
     ]
    }
   ],
   "source": [
    "satisfaction_map = {\n",
    "    1: \"Nada satisfecho\",\n",
    "    2: \"Insatisfecho\",\n",
    "    3: \"Satisfecho\",\n",
    "    4: \"Muy satisfecho\",\n",
    "}\n",
    "\n",
    "education_map = {\n",
    "    1: \"Sin estudios\",\n",
    "    2: \"Educaci√≥n b√°sica\",\n",
    "    3: \"FP/Bachiller\",\n",
    "    4: \"Estudios universitarios\",\n",
    "    5: \"Postgrado\",\n",
    "}\n",
    "\n",
    "job_level_map = {\n",
    "    1: \"Becario\",\n",
    "    2: \"Junior\",\n",
    "    3: \"Senior\",\n",
    "    4: \"Manager\",\n",
    "    5: \"Director\",\n",
    "}\n",
    "\n",
    "satisfaction_cols = [\n",
    "    \"env_satisfaction\",\n",
    "    \"job_involvement\",\n",
    "    \"job_satisfaction\",\n",
    "    \"performance_score\",\n",
    "    \"rel_satisfaction\",\n",
    "    \"work_life_balance\",\n",
    "]\n",
    "\n",
    "# Construir diccionario columna ‚Üí mapa\n",
    "mapeos_ordinales = {col: satisfaction_map for col in satisfaction_cols}\n",
    "mapeos_ordinales[\"education\"] = education_map\n",
    "mapeos_ordinales[\"job_level\"] = job_level_map\n",
    "\n",
    "\n",
    "df = mapear_columnas_ordinales(df, mapeos_ordinales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_categoricas(df, columnas, umbral_nulos_alto=0.20, umbral_nulos_bajo=0.05,\n",
    "                        umbral_moda_bajo=0.50, umbral_moda_medio=0.60, umbral_ventaja=0.20,\n",
    "                        etiqueta_unknown=\"Unknown\"):\n",
    "    \"\"\"\n",
    "    Imputa nulos en variables categ√≥ricas siguiendo reglas simples y justificables en EDA.\n",
    "\n",
    "    Reglas (resumen):\n",
    "    1) Si el % de nulos es ALTO (> umbral_nulos_alto, por defecto 20%) ‚Üí imputar con etiqueta_unknown.\n",
    "       - Motivo: imputar por moda con muchos nulos puede inventar demasiada informaci√≥n.\n",
    "\n",
    "    2) Si el % de nulos es BAJO (<= umbral_nulos_bajo, por defecto 5%) o MEDIO (entre 5% y 20%):\n",
    "       - Solo imputamos con la MODA si hay una categor√≠a realmente dominante.\n",
    "       - Para considerar \"dominante\" exigimos 2 condiciones:\n",
    "         a) La moda supera un umbral seg√∫n el % de nulos:\n",
    "            - Si nulos BAJOS: moda >= umbral_moda_bajo (50% por defecto)\n",
    "            - Si nulos MEDIOS: moda >= umbral_moda_medio (60% por defecto)\n",
    "         b) La moda tiene suficiente ventaja sobre la 2¬™ categor√≠a:\n",
    "            - (pct_moda - pct_segunda) >= umbral_ventaja (20 puntos porcentuales por defecto)\n",
    "\n",
    "       Si no se cumple lo anterior ‚Üí imputar con etiqueta_unknown.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada (se modifica y tambi√©n se devuelve).\n",
    "    columnas : list[str]\n",
    "        Lista de columnas categ√≥ricas a imputar.\n",
    "    umbral_nulos_alto : float, default 0.20\n",
    "        Por encima de este porcentaje de nulos se usa etiqueta_unknown.\n",
    "    umbral_nulos_bajo : float, default 0.05\n",
    "        Hasta este porcentaje de nulos se considera \"bajo\".\n",
    "    umbral_moda_bajo : float, default 0.50\n",
    "        Umbral m√≠nimo de la moda si los nulos son bajos.\n",
    "    umbral_moda_medio : float, default 0.60\n",
    "        Umbral m√≠nimo de la moda si los nulos son medios (5%-20%).\n",
    "    umbral_ventaja : float, default 0.20\n",
    "        Ventaja m√≠nima (en proporci√≥n, 0.20 = 20 puntos porcentuales) entre la moda y la 2¬™ categor√≠a.\n",
    "    etiqueta_unknown : str, default \"Unknown\"\n",
    "        Etiqueta para imputar cuando no se quiere usar la moda.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        El mismo DataFrame con los nulos imputados en las columnas indicadas.\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    for col in columnas:\n",
    "        print(f\"\\nüìå Analizando columna: {col}\")\n",
    "        \n",
    "        # Si la columna no existe, evitamos error y seguimos\n",
    "        if col not in df.columns:\n",
    "            print(f\"‚ùå La columna {col} no existe en el DataFrame. Se omite.\")\n",
    "            continue\n",
    "\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # Caso 1: muchos nulos -> Unknown directamente\n",
    "        if porcentaje_nulos > umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üî¥ Porcentaje de nulos > {umbral_nulos_alto:.0%} \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "        \n",
    "        # Calculamos frecuencias (sin nulos) para decidir si hay moda dominante\n",
    "        valores = df[col].value_counts(dropna=True)\n",
    "\n",
    "        if len(valores) == 0:\n",
    "            # No hay valores no nulos para decidir moda (columna vac√≠a o todo nulo)\n",
    "            print(\n",
    "                f\"   üî¥ No hay valores no nulos para decidir moda \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "\n",
    "        # Frecuencia y porcentaje de la moda\n",
    "        primero = valores.iloc[0]\n",
    "        pct_primero = primero / total # proporci√≥n sobre el total de filas\n",
    "\n",
    "        # Frecuencia y porcentaje de la segunda categor√≠a (si existe)\n",
    "        if len(valores) > 1:\n",
    "            segundo = valores.iloc[1]\n",
    "            pct_segundo = segundo / total\n",
    "        else:\n",
    "            pct_segundo = 0.0\n",
    "\n",
    "        ventaja = pct_primero - pct_segundo # ventaja de la moda frente a la 2¬™ (en proporci√≥n)\n",
    "\n",
    "        print(f\"   ‚Üí Moda: {valores.index[0]} ({pct_primero:.2%})\")\n",
    "        print(f\"   ‚Üí 2¬™ categor√≠a: {valores.index[1] if len(valores) > 1 else 'No existe'} ({pct_segundo:.2%})\")\n",
    "        print(f\"   ‚Üí Ventaja de la moda: {ventaja:.2%}\")\n",
    "\n",
    "        # Umbral de moda depende de si el % de nulos es bajo o medio\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            umbral_moda = umbral_moda_bajo\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        else:\n",
    "            umbral_moda = umbral_moda_medio\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos medios (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        \n",
    "        # Caso 2: imputar por moda solo si es dominante y con ventaja suficiente\n",
    "        if (pct_primero >= umbral_moda) and (ventaja >= umbral_ventaja):\n",
    "            moda = df[col].mode(dropna=True)[0]\n",
    "            print(\n",
    "                f\"   üü¢ La moda es dominante y con ventaja suficiente \"\n",
    "                f\"(‚â• {umbral_ventaja:.0%}) ‚Üí se imputan nulos con '{moda}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(moda)\n",
    "        else:\n",
    "            print(\n",
    "                f\"   üü° La moda NO es lo suficientemente dominante \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2073d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cols_cat = [c for c in cols_cat if c.lower() != \"attrition\"]  # excluimos attrition\n",
    "\n",
    "# normaliza falsos nulos solo en esas columnas\n",
    "df[cols_cat] = df[cols_cat].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "# imputaci√≥n\n",
    "df = imputar_categoricas(df, cols_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputar_numericas(df, columnas, umbral_nulos_bajo=0.05, umbral_nulos_alto=0.20,\n",
    "                      n_neighbors=5, crear_indicador_missing=True, usar_knn_en_alto=False):\n",
    "    \"\"\"\n",
    "    Imputa nulos en variables num√©ricas siguiendo reglas simples y justificables en EDA,\n",
    "    usando mediana (robusta) cuando el % de nulos es bajo y KNNImputer cuando es moderado.\n",
    "\n",
    "    Reglas (resumen):\n",
    "    1) Si el % de nulos es BAJO (<= umbral_nulos_bajo, por defecto 5%) ‚Üí imputar con mediana.\n",
    "       - Motivo: con pocos nulos, la mediana es estable y minimiza el efecto de outliers.\n",
    "\n",
    "    2) Si el % de nulos es MODERADO (> umbral_nulos_bajo y <= umbral_nulos_alto, por defecto 5%-20%)\n",
    "       ‚Üí imputar con KNNImputer (por defecto k=5) usando registros similares.\n",
    "       - Motivo: con m√°s nulos, KNN puede aprovechar el ‚Äúcontexto‚Äù de otras variables num√©ricas.\n",
    "\n",
    "    3) Si el % de nulos es ALTO (> umbral_nulos_alto, por defecto 20%):\n",
    "       - (Opcional) crear una variable indicadora de missingness: col + \"_missing\"\n",
    "       - Imputar con mediana por defecto (m√°s estable). Si quieres, puedes activar KNN tambi√©n en alto\n",
    "         con usar_knn_en_alto=True.\n",
    "\n",
    "    IMPORTANTE SOBRE KNN + ESCALADO:\n",
    "    KNN funciona con distancias entre filas. Si las columnas num√©ricas est√°n en escalas distintas\n",
    "    (por ejemplo, una en 0-10 y otra en 0-10.000), la columna de rango grande dominar√≠a la distancia.\n",
    "    Por eso hacemos:\n",
    "      - Escalado (StandardScaler) ‚Üí KNNImputer ‚Üí desescalado\n",
    "    As√≠ todas las columnas ‚Äúpesan‚Äù parecido al calcular similitud.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada (se modifica y tambi√©n se devuelve).\n",
    "    columnas : list[str]\n",
    "        Lista de columnas num√©ricas a imputar.\n",
    "    umbral_nulos_bajo : float, default 0.05\n",
    "        Hasta este porcentaje de nulos se considera \"bajo\".\n",
    "    umbral_nulos_alto : float, default 0.20\n",
    "        Por encima de este porcentaje de nulos se considera \"alto\".\n",
    "    n_neighbors : int, default 5\n",
    "        N√∫mero de vecinos (k) para KNNImputer.\n",
    "    crear_indicador_missing : bool, default True\n",
    "        Si True, cuando el % de nulos es alto se crea una columna col+\"_missing\" (0/1).\n",
    "    usar_knn_en_alto : bool, default False\n",
    "        Si True, en % de nulos alto tambi√©n se usa KNN (con escalado). Si False, se usa mediana.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        El mismo DataFrame con los nulos imputados en las columnas indicadas.\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    # Nos aseguramos de trabajar solo con columnas que existen\n",
    "    columnas_validas = [c for c in columnas if c in df.columns]\n",
    "    columnas_no_encontradas = [c for c in columnas if c not in df.columns]\n",
    "    for c in columnas_no_encontradas:\n",
    "        print(f\"{c} no existe en el DataFrame. Se omite.\")\n",
    "\n",
    "    # Tambi√©n nos aseguramos de que sean num√©ricas (por si te cuelas en la lista)\n",
    "    cols_num_df = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    columnas_validas = [c for c in columnas_validas if c in cols_num_df]\n",
    "\n",
    "    # Si no queda ninguna, salimos sin romper nada\n",
    "    if len(columnas_validas) == 0:\n",
    "        print(\"No hay columnas num√©ricas v√°lidas para imputar.\")\n",
    "        return df\n",
    "\n",
    "    # Preparamos imputador de mediana (lo reutilizamos)\n",
    "    imputer_mediana = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # Para KNN con escalado, necesitamos un ‚Äúbloque‚Äù num√©rico:\n",
    "    # Usamos TODAS las num√©ricas del DF, porque KNN se beneficia de m√°s contexto.\n",
    "    # (Esto NO significa que imputemos todas: solo guardamos de vuelta las columnas objetivo.)\n",
    "    cols_num_contexto = cols_num_df\n",
    "\n",
    "    for col in columnas_validas:\n",
    "        print(f\"\\nüìå Analizando columna num√©rica: {col}\")\n",
    "\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # CASO 1: % de nulos bajo -> mediana\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            print(\n",
    "                f\"   üü¢ Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con MEDIANA (SimpleImputer)\"\n",
    "            )\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "            continue\n",
    "\n",
    "        # CASO 2: % de nulos moderado -> KNN con escalado\n",
    "        if porcentaje_nulos <= umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üü° Nulos moderados (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            # 1) Cogemos el bloque num√©rico completo (contexto)\n",
    "            X = df[cols_num_contexto].copy()\n",
    "\n",
    "            # 2) Escalamos (standardization): (x - media) / desviaci√≥n\n",
    "            #    Esto hace comparables las columnas para calcular distancias.\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # 3) Imputamos en el espacio escalado\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            # 4) Desescalamos para volver a las unidades originales\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "\n",
    "            # 5) Volvemos a DataFrame para poder asignar por columnas\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            # 6) Solo guardamos la columna objetivo (para no tocar otras num√©ricas fuera de tu lista)\n",
    "            df[col] = X_imputed[col]\n",
    "\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "            continue\n",
    "\n",
    "        # CASO 3: % de nulos alto\n",
    "        print(\n",
    "            f\"   üî¥ Nulos altos (> {umbral_nulos_alto:.0%}) \"\n",
    "            f\"‚Üí se considera missingness + imputaci√≥n robusta\"\n",
    "        )\n",
    "\n",
    "        if crear_indicador_missing:\n",
    "            indicador = f\"{col}_missing\"\n",
    "            # 1 si era nulo, 0 si no\n",
    "            df[indicador] = df[col].isnull().astype(int)\n",
    "            print(f\"   ‚Üí Se crea indicador de missingness: {indicador} (1=nulo, 0=no nulo)\")\n",
    "\n",
    "        if usar_knn_en_alto:\n",
    "            print(\n",
    "                f\"   üü† usar_knn_en_alto=True \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            X = df[cols_num_contexto].copy()\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            df[col] = X_imputed[col]\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "\n",
    "        else:\n",
    "            print(\"   üü† Se imputa con MEDIANA (SimpleImputer) por estabilidad.\")\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9facd556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_general(\n",
    "    df,\n",
    "    id_columna='employee_number',\n",
    "    mapeo_tipos=None,\n",
    "    mapeos_texto=None,\n",
    "    mapeos_ordinales=None,\n",
    "    columnas_categoricas_nulos=None,\n",
    "    columnas_numericas_nulos=None,\n",
    "    mostrar_resumen=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Funci√≥n general de limpieza que llama a las funciones individuales previamente definidas.\n",
    "\n",
    "    Pasos incluidos:\n",
    "    1. Normalizaci√≥n de nombres de columnas (snake_case)\n",
    "    2. Establecer columna ID como √≠ndice y renombrarla a 'id'\n",
    "    3. Eliminaci√≥n de filas duplicadas\n",
    "    4. Eliminaci√≥n de columnas sin aporte anal√≠tico\n",
    "    5. Conversi√≥n de tipos de columnas\n",
    "    6. Normalizaci√≥n de columnas de texto con mapeos opcionales\n",
    "    7. Mapeo de columnas ordinales\n",
    "    8. Imputaci√≥n de nulos en columnas categ√≥ricas\n",
    "    9. Imputaci√≥n de nulos en columnas num√©ricas\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame limpio listo para el an√°lisis\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Normalizar nombres de columnas\n",
    "    df.columns = normalizar_nombres_columnas(df.columns.tolist(), mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # 2. Establecer ID como √≠ndice y renombrar a 'id'\n",
    "    df = usar_columna_como_indice(df, columna_original=id_columna, indice='id')\n",
    "\n",
    "    # 3. Eliminar duplicados\n",
    "    df = eliminar_filas_duplicadas(df)\n",
    "\n",
    "    # 4. Eliminar columnas sin aporte anal√≠tico\n",
    "    df = eliminar_columnas_sin_aporte_analitico(df)\n",
    "\n",
    "    # 5. Conversi√≥n de tipos de columnas\n",
    "    if mapeo_tipos:\n",
    "        df = convertir_tipos_columnas(df, mapeo_tipos, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # 6. Normalizaci√≥n de columnas de texto\n",
    "    if mapeos_texto:\n",
    "        df = normalizar_columnas_texto(df, mapeos_reemplazo=mapeos_texto, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # 7. Mapeo de columnas ordinales\n",
    "    if mapeos_ordinales:\n",
    "        df = mapear_columnas_ordinales(df, mapeos_ordinales, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # 8. Imputaci√≥n de nulos en columnas categ√≥ricas\n",
    "    if columnas_categoricas_nulos:\n",
    "        df = imputar_categoricas(df, columnas_categoricas_nulos)\n",
    "\n",
    "    # 9. Imputaci√≥n de nulos en columnas num√©ricas\n",
    "    if columnas_numericas_nulos:\n",
    "        df = imputar_numericas(df, columnas_numericas_nulos)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"\\nüü¢ Limpieza general completada.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/hr_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
