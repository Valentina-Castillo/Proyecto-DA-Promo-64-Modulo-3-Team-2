{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def imputar_categoricas(df, columnas, umbral_nulos_alto=0.20, umbral_nulos_bajo=0.05,\n",
    "                        umbral_moda_bajo=0.50, umbral_moda_medio=0.60, umbral_ventaja=0.20,\n",
    "                        etiqueta_unknown=\"Unknown\"):\n",
    "    \"\"\"\n",
    "    Imputa nulos en variables categ√≥ricas siguiendo reglas simples y justificables en EDA.\n",
    "\n",
    "    Reglas (resumen):\n",
    "    1) Si el % de nulos es ALTO (> umbral_nulos_alto, por defecto 20%) ‚Üí imputar con etiqueta_unknown.\n",
    "       - Motivo: imputar por moda con muchos nulos puede inventar demasiada informaci√≥n.\n",
    "\n",
    "    2) Si el % de nulos es BAJO (<= umbral_nulos_bajo, por defecto 5%) o MEDIO (entre 5% y 20%):\n",
    "       - Solo imputamos con la MODA si hay una categor√≠a realmente dominante.\n",
    "       - Para considerar \"dominante\" exigimos 2 condiciones:\n",
    "         a) La moda supera un umbral seg√∫n el % de nulos:\n",
    "            - Si nulos BAJOS: moda >= umbral_moda_bajo (50% por defecto)\n",
    "            - Si nulos MEDIOS: moda >= umbral_moda_medio (60% por defecto)\n",
    "         b) La moda tiene suficiente ventaja sobre la 2¬™ categor√≠a:\n",
    "            - (pct_moda - pct_segunda) >= umbral_ventaja (20 puntos porcentuales por defecto)\n",
    "\n",
    "       Si no se cumple lo anterior ‚Üí imputar con etiqueta_unknown.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada (se modifica y tambi√©n se devuelve).\n",
    "    columnas : list[str]\n",
    "        Lista de columnas categ√≥ricas a imputar.\n",
    "    umbral_nulos_alto : float, default 0.20\n",
    "        Por encima de este porcentaje de nulos se usa etiqueta_unknown.\n",
    "    umbral_nulos_bajo : float, default 0.05\n",
    "        Hasta este porcentaje de nulos se considera \"bajo\".\n",
    "    umbral_moda_bajo : float, default 0.50\n",
    "        Umbral m√≠nimo de la moda si los nulos son bajos.\n",
    "    umbral_moda_medio : float, default 0.60\n",
    "        Umbral m√≠nimo de la moda si los nulos son medios (5%-20%).\n",
    "    umbral_ventaja : float, default 0.20\n",
    "        Ventaja m√≠nima (en proporci√≥n, 0.20 = 20 puntos porcentuales) entre la moda y la 2¬™ categor√≠a.\n",
    "    etiqueta_unknown : str, default \"Unknown\"\n",
    "        Etiqueta para imputar cuando no se quiere usar la moda.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        El mismo DataFrame con los nulos imputados en las columnas indicadas.\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    for col in columnas:\n",
    "        print(f\"\\nüìå Analizando columna: {col}\")\n",
    "        \n",
    "        # Si la columna no existe, evitamos error y seguimos\n",
    "        if col not in df.columns:\n",
    "            print(f\"‚ùå La columna {col} no existe en el DataFrame. Se omite.\")\n",
    "            continue\n",
    "\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # Caso 1: muchos nulos -> Unknown directamente\n",
    "        if porcentaje_nulos > umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üî¥ Porcentaje de nulos > {umbral_nulos_alto:.0%} \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "        \n",
    "        # Calculamos frecuencias (sin nulos) para decidir si hay moda dominante\n",
    "        valores = df[col].value_counts(dropna=True)\n",
    "\n",
    "        if len(valores) == 0:\n",
    "            # No hay valores no nulos para decidir moda (columna vac√≠a o todo nulo)\n",
    "            print(\n",
    "                f\"   üî¥ No hay valores no nulos para decidir moda \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "            continue\n",
    "\n",
    "        # Frecuencia y porcentaje de la moda\n",
    "        primero = valores.iloc[0]\n",
    "        pct_primero = primero / total # proporci√≥n sobre el total de filas\n",
    "\n",
    "        # Frecuencia y porcentaje de la segunda categor√≠a (si existe)\n",
    "        if len(valores) > 1:\n",
    "            segundo = valores.iloc[1]\n",
    "            pct_segundo = segundo / total\n",
    "        else:\n",
    "            pct_segundo = 0.0\n",
    "\n",
    "        ventaja = pct_primero - pct_segundo # ventaja de la moda frente a la 2¬™ (en proporci√≥n)\n",
    "\n",
    "        print(f\"   ‚Üí Moda: {valores.index[0]} ({pct_primero:.2%})\")\n",
    "        print(f\"   ‚Üí 2¬™ categor√≠a: {valores.index[1] if len(valores) > 1 else 'No existe'} ({pct_segundo:.2%})\")\n",
    "        print(f\"   ‚Üí Ventaja de la moda: {ventaja:.2%}\")\n",
    "\n",
    "        # Umbral de moda depende de si el % de nulos es bajo o medio\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            umbral_moda = umbral_moda_bajo\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        else:\n",
    "            umbral_moda = umbral_moda_medio\n",
    "            print(\n",
    "                f\"   ‚Üí Nulos medios (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}), \"\n",
    "                f\"umbral de moda requerido: {umbral_moda:.0%}\"\n",
    "            )\n",
    "        \n",
    "        # Caso 2: imputar por moda solo si es dominante y con ventaja suficiente\n",
    "        if (pct_primero >= umbral_moda) and (ventaja >= umbral_ventaja):\n",
    "            moda = df[col].mode(dropna=True)[0]\n",
    "            print(\n",
    "                f\"   üü¢ La moda es dominante y con ventaja suficiente \"\n",
    "                f\"(‚â• {umbral_ventaja:.0%}) ‚Üí se imputan nulos con '{moda}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(moda)\n",
    "        else:\n",
    "            print(\n",
    "                f\"   üü° La moda NO es lo suficientemente dominante \"\n",
    "                f\"‚Üí se crea la categor√≠a '{etiqueta_unknown}'\"\n",
    "            )\n",
    "            df[col] = df[col].fillna(etiqueta_unknown)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cols_cat = [c for c in cols_cat if c.lower() != \"attrition\"]  # excluimos attrition\n",
    "\n",
    "# normaliza falsos nulos solo en esas columnas\n",
    "df[cols_cat] = df[cols_cat].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "\n",
    "# imputaci√≥n\n",
    "df = imputar_categoricas(df, cols_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def imputar_numericas(df, columnas, umbral_nulos_bajo=0.05, umbral_nulos_alto=0.20,\n",
    "                      n_neighbors=5, crear_indicador_missing=True, usar_knn_en_alto=False):\n",
    "    \"\"\"\n",
    "    Imputa nulos en variables num√©ricas siguiendo reglas simples y justificables en EDA,\n",
    "    usando mediana (robusta) cuando el % de nulos es bajo y KNNImputer cuando es moderado.\n",
    "\n",
    "    Reglas (resumen):\n",
    "    1) Si el % de nulos es BAJO (<= umbral_nulos_bajo, por defecto 5%) ‚Üí imputar con mediana.\n",
    "       - Motivo: con pocos nulos, la mediana es estable y minimiza el efecto de outliers.\n",
    "\n",
    "    2) Si el % de nulos es MODERADO (> umbral_nulos_bajo y <= umbral_nulos_alto, por defecto 5%-20%)\n",
    "       ‚Üí imputar con KNNImputer (por defecto k=5) usando registros similares.\n",
    "       - Motivo: con m√°s nulos, KNN puede aprovechar el ‚Äúcontexto‚Äù de otras variables num√©ricas.\n",
    "\n",
    "    3) Si el % de nulos es ALTO (> umbral_nulos_alto, por defecto 20%):\n",
    "       - (Opcional) crear una variable indicadora de missingness: col + \"_missing\"\n",
    "       - Imputar con mediana por defecto (m√°s estable). Si quieres, puedes activar KNN tambi√©n en alto\n",
    "         con usar_knn_en_alto=True.\n",
    "\n",
    "    IMPORTANTE SOBRE KNN + ESCALADO:\n",
    "    KNN funciona con distancias entre filas. Si las columnas num√©ricas est√°n en escalas distintas\n",
    "    (por ejemplo, una en 0-10 y otra en 0-10.000), la columna de rango grande dominar√≠a la distancia.\n",
    "    Por eso hacemos:\n",
    "      - Escalado (StandardScaler) ‚Üí KNNImputer ‚Üí desescalado\n",
    "    As√≠ todas las columnas ‚Äúpesan‚Äù parecido al calcular similitud.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada (se modifica y tambi√©n se devuelve).\n",
    "    columnas : list[str]\n",
    "        Lista de columnas num√©ricas a imputar.\n",
    "    umbral_nulos_bajo : float, default 0.05\n",
    "        Hasta este porcentaje de nulos se considera \"bajo\".\n",
    "    umbral_nulos_alto : float, default 0.20\n",
    "        Por encima de este porcentaje de nulos se considera \"alto\".\n",
    "    n_neighbors : int, default 5\n",
    "        N√∫mero de vecinos (k) para KNNImputer.\n",
    "    crear_indicador_missing : bool, default True\n",
    "        Si True, cuando el % de nulos es alto se crea una columna col+\"_missing\" (0/1).\n",
    "    usar_knn_en_alto : bool, default False\n",
    "        Si True, en % de nulos alto tambi√©n se usa KNN (con escalado). Si False, se usa mediana.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        El mismo DataFrame con los nulos imputados en las columnas indicadas.\n",
    "    \"\"\"\n",
    "\n",
    "    total = len(df)\n",
    "\n",
    "    # Nos aseguramos de trabajar solo con columnas que existen\n",
    "    columnas_validas = [c for c in columnas if c in df.columns]\n",
    "    columnas_no_encontradas = [c for c in columnas if c not in df.columns]\n",
    "    for c in columnas_no_encontradas:\n",
    "        print(f\"{c} no existe en el DataFrame. Se omite.\")\n",
    "\n",
    "    # Tambi√©n nos aseguramos de que sean num√©ricas (por si te cuelas en la lista)\n",
    "    cols_num_df = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    columnas_validas = [c for c in columnas_validas if c in cols_num_df]\n",
    "\n",
    "    # Si no queda ninguna, salimos sin romper nada\n",
    "    if len(columnas_validas) == 0:\n",
    "        print(\"No hay columnas num√©ricas v√°lidas para imputar.\")\n",
    "        return df\n",
    "\n",
    "    # Preparamos imputador de mediana (lo reutilizamos)\n",
    "    imputer_mediana = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # Para KNN con escalado, necesitamos un ‚Äúbloque‚Äù num√©rico:\n",
    "    # Usamos TODAS las num√©ricas del DF, porque KNN se beneficia de m√°s contexto.\n",
    "    # (Esto NO significa que imputemos todas: solo guardamos de vuelta las columnas objetivo.)\n",
    "    cols_num_contexto = cols_num_df\n",
    "\n",
    "    for col in columnas_validas:\n",
    "        print(f\"\\nüìå Analizando columna num√©rica: {col}\")\n",
    "\n",
    "        nulos = df[col].isnull().sum()\n",
    "        porcentaje_nulos = nulos / total if total > 0 else 0\n",
    "        print(f\"   ‚Üí Nulos: {nulos} de {total} ({porcentaje_nulos:.2%})\")\n",
    "\n",
    "        # CASO 1: % de nulos bajo -> mediana\n",
    "        if porcentaje_nulos <= umbral_nulos_bajo:\n",
    "            print(\n",
    "                f\"   üü¢ Nulos bajos (‚â§ {umbral_nulos_bajo:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con MEDIANA (SimpleImputer)\"\n",
    "            )\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "            continue\n",
    "\n",
    "        # CASO 2: % de nulos moderado -> KNN con escalado\n",
    "        if porcentaje_nulos <= umbral_nulos_alto:\n",
    "            print(\n",
    "                f\"   üü° Nulos moderados (> {umbral_nulos_bajo:.0%} y ‚â§ {umbral_nulos_alto:.0%}) \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            # 1) Cogemos el bloque num√©rico completo (contexto)\n",
    "            X = df[cols_num_contexto].copy()\n",
    "\n",
    "            # 2) Escalamos (standardization): (x - media) / desviaci√≥n\n",
    "            #    Esto hace comparables las columnas para calcular distancias.\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            # 3) Imputamos en el espacio escalado\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            # 4) Desescalamos para volver a las unidades originales\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "\n",
    "            # 5) Volvemos a DataFrame para poder asignar por columnas\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            # 6) Solo guardamos la columna objetivo (para no tocar otras num√©ricas fuera de tu lista)\n",
    "            df[col] = X_imputed[col]\n",
    "\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "            continue\n",
    "\n",
    "        # CASO 3: % de nulos alto\n",
    "        print(\n",
    "            f\"   üî¥ Nulos altos (> {umbral_nulos_alto:.0%}) \"\n",
    "            f\"‚Üí se considera missingness + imputaci√≥n robusta\"\n",
    "        )\n",
    "\n",
    "        if crear_indicador_missing:\n",
    "            indicador = f\"{col}_missing\"\n",
    "            # 1 si era nulo, 0 si no\n",
    "            df[indicador] = df[col].isnull().astype(int)\n",
    "            print(f\"   ‚Üí Se crea indicador de missingness: {indicador} (1=nulo, 0=no nulo)\")\n",
    "\n",
    "        if usar_knn_en_alto:\n",
    "            print(\n",
    "                f\"   üü† usar_knn_en_alto=True \"\n",
    "                f\"‚Üí imputaci√≥n con KNN (k={n_neighbors}) + ESCALADO\"\n",
    "            )\n",
    "\n",
    "            X = df[cols_num_contexto].copy()\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "            knn = KNNImputer(n_neighbors=n_neighbors)\n",
    "            X_imputed_scaled = knn.fit_transform(X_scaled)\n",
    "\n",
    "            X_imputed = scaler.inverse_transform(X_imputed_scaled)\n",
    "            X_imputed = pd.DataFrame(X_imputed, columns=cols_num_contexto, index=df.index)\n",
    "\n",
    "            df[col] = X_imputed[col]\n",
    "            print(f\"   ‚úÖ {col} imputada con KNN + escalado (solo se asigna esta columna).\")\n",
    "\n",
    "        else:\n",
    "            print(\"   üü† Se imputa con MEDIANA (SimpleImputer) por estabilidad.\")\n",
    "            df[[col]] = imputer_mediana.fit_transform(df[[col]])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f85d2",
   "metadata": {},
   "source": [
    "---\n",
    "## **10. FUNCI√ìN DE LIMPIEZA GENERAL**\n",
    "\n",
    "Esta funci√≥n integra todos los pasos anteriores en un solo proceso automatizado.\n",
    "Es √∫til cuando quieres aplicar todo el flujo de limpieza de una sola vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb05e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza_general(\n",
    "    df,\n",
    "    id_columna='employee_number',\n",
    "    mapeo_tipos=None,\n",
    "    mapeos_texto=None,\n",
    "    mapeos_ordinales=None,\n",
    "    columnas_categoricas_nulos=None,\n",
    "    columnas_numericas_nulos=None,\n",
    "    mostrar_resumen=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Ejecuta el proceso completo de limpieza de datos en un DataFrame.\n",
    "    \n",
    "    Esta funci√≥n orquesta todos los pasos de limpieza en el orden correcto:\n",
    "    1. Normalizaci√≥n de nombres de columnas (snake_case)\n",
    "    2. Establecer columna ID como √≠ndice\n",
    "    3. Eliminaci√≥n de filas duplicadas\n",
    "    4. Eliminaci√≥n de columnas sin aporte anal√≠tico\n",
    "    5. Conversi√≥n de tipos de datos\n",
    "    6. Normalizaci√≥n de columnas de texto\n",
    "    7. Mapeo de columnas ordinales\n",
    "    8. Imputaci√≥n de nulos en categ√≥ricas\n",
    "    9. Imputaci√≥n de nulos en num√©ricas\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame original a limpiar\n",
    "    id_columna : str, default='employee_number'\n",
    "        Nombre de la columna que se usar√° como √≠ndice\n",
    "    mapeo_tipos : dict, optional\n",
    "        Diccionario de conversi√≥n de tipos {'columna': tipo}\n",
    "    mapeos_texto : dict, optional\n",
    "        Diccionario de reemplazos en texto {'columna': {'viejo': 'nuevo'}}\n",
    "    mapeos_ordinales : dict, optional\n",
    "        Diccionario de mapeos ordinales {'columna': {1: 'etiqueta'}}\n",
    "    columnas_categoricas_nulos : list, optional\n",
    "        Lista de columnas categ√≥ricas donde imputar nulos\n",
    "    columnas_numericas_nulos : list, optional\n",
    "        Lista de columnas num√©ricas donde imputar nulos\n",
    "    mostrar_resumen : bool, default=True\n",
    "        Si True, imprime resumen de cada paso\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame limpio y listo para an√°lisis\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear copia para no modificar el DataFrame original\n",
    "    df = df.copy()\n",
    "\n",
    "    # PASO 1: Normalizar nombres de columnas\n",
    "    df.columns = normalizar_nombres_columnas(df.columns.tolist(), mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 2: Establecer ID como √≠ndice\n",
    "    df = usar_columna_como_indice(df, columna_original=id_columna, indice='id')\n",
    "\n",
    "    # PASO 3: Eliminar duplicados\n",
    "    df = eliminar_filas_duplicadas(df)\n",
    "\n",
    "    # PASO 4: Eliminar columnas sin aporte anal√≠tico\n",
    "    df = eliminar_columnas_sin_aporte_analitico(df)\n",
    "\n",
    "    # PASO 5: Conversi√≥n de tipos (si se proporcion√≥ mapeo)\n",
    "    if mapeo_tipos:\n",
    "        df = convertir_tipos_columnas(df, mapeo_tipos, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 6: Normalizaci√≥n de texto (si se proporcionaron mapeos)\n",
    "    if mapeos_texto:\n",
    "        df = normalizar_columnas_texto(df, mapeos_reemplazo=mapeos_texto, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 7: Mapeo de ordinales (si se proporcionaron mapeos)\n",
    "    if mapeos_ordinales:\n",
    "        df = mapear_columnas_ordinales(df, mapeos_ordinales, mostrar_resumen=mostrar_resumen)\n",
    "\n",
    "    # PASO 8: Imputaci√≥n de categ√≥ricas (si se especificaron columnas)\n",
    "    if columnas_categoricas_nulos:\n",
    "        df = imputar_categoricas(df, columnas_categoricas_nulos)\n",
    "\n",
    "    # PASO 9: Imputaci√≥n de num√©ricas (si se especificaron columnas)\n",
    "    if columnas_numericas_nulos:\n",
    "        df = imputar_numericas(df, columnas_numericas_nulos)\n",
    "\n",
    "    if mostrar_resumen:\n",
    "        print(\"\\nüü¢ Limpieza general completada.\")\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
